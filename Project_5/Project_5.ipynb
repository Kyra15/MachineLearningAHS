{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T12:02:58.723742Z",
     "iopub.status.busy": "2025-10-27T12:02:58.723239Z",
     "iopub.status.idle": "2025-10-27T12:02:58.737007Z",
     "shell.execute_reply": "2025-10-27T12:02:58.735616Z",
     "shell.execute_reply.started": "2025-10-27T12:02:58.723682Z"
    }
   },
   "source": [
    "Using machine learning, identify handwritten cursive letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T12:19:18.646824Z",
     "iopub.status.busy": "2025-10-20T12:19:18.646086Z",
     "iopub.status.idle": "2025-10-20T12:19:22.818372Z",
     "shell.execute_reply": "2025-10-20T12:19:22.816438Z",
     "shell.execute_reply.started": "2025-10-20T12:19:18.646773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /home/jupyter-251201/.local/lib/python3.10/site-packages (from opencv-python) (2.2.6)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T12:21:52.181848Z",
     "iopub.status.busy": "2025-10-27T12:21:52.181384Z",
     "iopub.status.idle": "2025-10-27T12:21:53.043894Z",
     "shell.execute_reply": "2025-10-27T12:21:53.042817Z",
     "shell.execute_reply.started": "2025-10-27T12:21:52.181819Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:10:03.061664Z",
     "iopub.status.busy": "2025-10-28T12:10:03.060910Z",
     "iopub.status.idle": "2025-10-28T12:10:06.656979Z",
     "shell.execute_reply": "2025-10-28T12:10:06.655514Z",
     "shell.execute_reply.started": "2025-10-28T12:10:03.061614Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"cursiveData.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"Data2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things I'm thinking about:\n",
    "- black and white\n",
    "- scale images\n",
    "- canny edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert files\n",
    "\n",
    "crop data so that each corner is touching white (should work?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:21:12.125969Z",
     "iopub.status.busy": "2025-10-28T12:21:12.125561Z",
     "iopub.status.idle": "2025-10-28T12:21:12.148529Z",
     "shell.execute_reply": "2025-10-28T12:21:12.147663Z",
     "shell.execute_reply.started": "2025-10-28T12:21:12.125940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 106 36 415\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# look for types of file endings\n",
    "png_count = len(glob.glob('Data2/Cursive/**/*.png', recursive=True))\n",
    "jpg_count = len(glob.glob('Data2/Cursive/**/*.jpg', recursive=True))\n",
    "jpeg_count = len(glob.glob('Data2/Cursive/**/*.jpeg', recursive=True))\n",
    "heic_count = len(glob.glob('Data2/Cursive/**/*.HEIC', recursive=True))\n",
    "print(png_count, jpg_count, jpeg_count, heic_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:25:48.065159Z",
     "iopub.status.busy": "2025-10-28T12:25:48.064553Z",
     "iopub.status.idle": "2025-10-28T12:25:48.074527Z",
     "shell.execute_reply": "2025-10-28T12:25:48.073562Z",
     "shell.execute_reply.started": "2025-10-28T12:25:48.065118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# file folder counts\n",
    "dirs = 0\n",
    "files = 0\n",
    "\n",
    "for root, dirnames, filenames in os.walk(\"Data2/Cursive\"):\n",
    "    dirs += len(dirnames)\n",
    "    files += len(filenames)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:33:54.965929Z",
     "iopub.status.busy": "2025-10-28T12:33:54.965226Z",
     "iopub.status.idle": "2025-10-28T12:33:55.022143Z",
     "shell.execute_reply": "2025-10-28T12:33:55.020461Z",
     "shell.execute_reply.started": "2025-10-28T12:33:54.965867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data2/Cursive/S10/S13 | 76\n",
      "Data2/Cursive/S11 | 2\n",
      "Data2/Cursive/S14 | 5\n",
      "Data2/Cursive/S17 | 25\n",
      "Data2/Cursive/S33 | 25\n",
      "Data2/Cursive/S34 | 10\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter()\n",
    "\n",
    "for f in Path(\"Data2/Cursive\").rglob(\"*\"):\n",
    "        if f.is_file():\n",
    "            counts[str(f.parent)] += 1\n",
    "# print(counts)\n",
    "\n",
    "for folder, num_files in sorted(counts.items()):\n",
    "        if num_files != 26:\n",
    "            print(f\"{folder:} | {num_files}\")\n",
    "\n",
    "# get rid of these?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to:\n",
    "- Label Data\n",
    "- Crop images (content aware)\n",
    "- Rotate (not sure)\n",
    "- Black and white (opencv)\n",
    "- Canny edge (highlight edges so the letters are easier to pick out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T12:24:41.842009Z",
     "iopub.status.busy": "2025-10-27T12:24:41.841424Z",
     "iopub.status.idle": "2025-10-27T12:24:45.030825Z",
     "shell.execute_reply": "2025-10-27T12:24:45.028320Z",
     "shell.execute_reply.started": "2025-10-27T12:24:41.841966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyCAIR in /home/jupyter-251201/.local/lib/python3.10/site-packages (0.1.13)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "\u001b[33m  WARNING: The script natsort is installed in '/home/jupyter-251201/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed natsort-8.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyCAIR\n",
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:30:34.950754Z",
     "iopub.status.busy": "2025-10-28T12:30:34.950372Z",
     "iopub.status.idle": "2025-10-28T12:30:35.428455Z",
     "shell.execute_reply": "2025-10-28T12:30:35.427471Z",
     "shell.execute_reply.started": "2025-10-28T12:30:34.950724Z"
    }
   },
   "outputs": [],
   "source": [
    "destination_path = 'Data2/Cursive'\n",
    "target_path = 'BetterData2'\n",
    "\n",
    "format_of_your_images = 'png'\n",
    "\n",
    "all_the_files = Path(destination_path).rglob(f'*.{format_of_your_images}')\n",
    "\n",
    "for f in all_the_files:\n",
    "    p = cv2.imread(str(f))\n",
    "    gray = cv2.cvtColor(p, cv2.COLOR_BGR2GRAY)\n",
    "    canny = cv2.Canny(gray, 50, 150)\n",
    "    cv2.imwrite(f'{target_path}/{f.name}', canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T12:39:30.337026Z",
     "iopub.status.busy": "2025-10-27T12:39:30.336419Z",
     "iopub.status.idle": "2025-10-27T12:39:30.399723Z",
     "shell.execute_reply": "2025-10-27T12:39:30.398437Z",
     "shell.execute_reply.started": "2025-10-27T12:39:30.336973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (2060, 1545, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"butt.jpg\")\n",
    "print(type(image), image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:35:08.032367Z",
     "iopub.status.busy": "2025-10-28T12:35:08.031515Z",
     "iopub.status.idle": "2025-10-28T12:35:08.833267Z",
     "shell.execute_reply": "2025-10-28T12:35:08.832113Z",
     "shell.execute_reply.started": "2025-10-28T12:35:08.032336Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/773 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyCAIR\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseam_carve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cropByColumn\n\u001b[0;32m----> 3\u001b[0m seam_img, col_cropped \u001b[38;5;241m=\u001b[39m \u001b[43mcropByColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_seams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlsit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlsit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyCAIR/seam_carve.py:164\u001b[0m, in \u001b[0;36mcropByColumn\u001b[0;34m(image, display_seams, generate, lsit, scale_c, fromRow)\u001b[0m\n\u001b[1;32m    162\u001b[0m \t\t\t\u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \t\u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m \t\timage \u001b[38;5;241m=\u001b[39m \u001b[43mdrawSeam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    165\u001b[0m \t\tcrop \u001b[38;5;241m=\u001b[39m carve(crop)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, crop\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyCAIR/seam_carve.py:64\u001b[0m, in \u001b[0;36mdrawSeam\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrawSeam\u001b[39m(image):\n\u001b[1;32m     63\u001b[0m \trows, columns, _ \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 64\u001b[0m \tcMap, goback \u001b[38;5;241m=\u001b[39m \u001b[43mgetMaps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((rows, columns), dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m     68\u001b[0m \tj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(cMap[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyCAIR/seam_carve.py:43\u001b[0m, in \u001b[0;36mgetMaps\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     40\u001b[0m energy_map \u001b[38;5;241m=\u001b[39m getEnergy(image)\n\u001b[1;32m     42\u001b[0m current_map \u001b[38;5;241m=\u001b[39m energy_map\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 43\u001b[0m goback \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(current_map, dtype \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, rows):\n\u001b[1;32m     46\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, columns):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:397\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    392\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    403\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from pyCAIR.seam_carve import cropByColumn\n",
    "\n",
    "seam_img, col_cropped = cropByColumn(image=image, display_seams=1, lsit=lsit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale images\n",
    "# https://www.geeksforgeeks.org/python/resize-multiple-images-using-opencv-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:49:41.064452Z",
     "iopub.status.busy": "2025-10-20T11:49:41.064152Z",
     "iopub.status.idle": "2025-10-20T11:49:41.074199Z",
     "shell.execute_reply": "2025-10-20T11:49:41.073403Z",
     "shell.execute_reply.started": "2025-10-20T11:49:41.064425Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "\n",
    "def infrence(text):\n",
    "\n",
    "    # load everything in\n",
    "    model = joblib.load(\"./models/best_mnb.pkl\")\n",
    "    vectorizer = joblib.load(\"./models/vectorizer.pkl\")\n",
    "    scaler = joblib.load(\"./models/scaler.pkl\")\n",
    "    feature_params = joblib.load(\"./models/feature_params.pkl\")\n",
    "    \n",
    "    s_words = feature_params[0]\n",
    "    h_words = feature_params[1]\n",
    "    good_emails = feature_params[2]\n",
    "\n",
    "    # clean and tokenize the text\n",
    "    cleaned = re.sub(r'[^A-Za-z\\s]', '', text).lower()\n",
    "    tokens = [word for word in cleaned.split() if word not in stopwords and len(word) > 2]\n",
    "    token_counter = collections.Counter(tokens)\n",
    "\n",
    "    # freq of most common words\n",
    "    spam_freq = np.sum([token_counter[word.lower()] for word in s_words])\n",
    "    ham_freq = np.sum([token_counter[word.lower()] for word in h_words])\n",
    "\n",
    "    # amt of punctuation\n",
    "    punctuation_chars = string.punctuation\n",
    "    regex_pat = \"[\" + re.escape(punctuation_chars) + \"]\"\n",
    "    punct_freq = len(re.findall(regex_pat, text))\n",
    "\n",
    "    # good email domain\n",
    "    good_email_count = sum(1 for x in good_emails if x in text.lower())\n",
    "\n",
    "    # msg length\n",
    "    msg_len = len(text)\n",
    "\n",
    "    # create df of numeric\n",
    "    numeric_features = pd.DataFrame([[spam_freq, punct_freq, msg_len, ham_freq, good_email_count]],\n",
    "                                columns=['spam_most_common_freq','punctuation_freq','msg_len','ham_most_common_freq','good_email'])\n",
    "    numeric_features_scaled = scaler.transform(numeric_features)\n",
    "\n",
    "    # vectorize words\n",
    "    text_features = vectorizer.transform([text])\n",
    "    X = hstack([text_features, csr_matrix(numeric_features_scaled)])\n",
    "    \n",
    "    # predcit!\n",
    "    prediction = model.predict(X)\n",
    "        \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:49:41.075759Z",
     "iopub.status.busy": "2025-10-20T11:49:41.075326Z",
     "iopub.status.idle": "2025-10-20T11:49:41.116897Z",
     "shell.execute_reply": "2025-10-20T11:49:41.115576Z",
     "shell.execute_reply.started": "2025-10-20T11:49:41.075732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "test1 = '''Subject: stock market information\n",
    "\n",
    "sender : trinity venture , inc . address : 1911 westmead # 2710 , houston , tx 7707 call fax toll free : 877-393 - 7237 hours : 9 5 pm cst hi , receive e-mail address someone interest stock market information . e-mail informational purpose . offer sell solicit security . wish receive type information , please click \" reply \" put \" remove \" subject . permanently remove address our database . news help due diligence abrg , www . yahoo . com click \" stock quote \" . put abrg symbol lookup area click \" quote \" . happy invest ! - dean casia president trinity venture , inc . news release ambra resources group inc . # 610-800 west pender street vancouver , b . c . canada v6c 2v6 symbol abrg ( otc : bb ) acquisition venture oil & gas , inc . ambra resources group inc . adds projects ambra vancouver , british columbium - 4 , 1999 ambra resource group inc . ( otc bb : abrg ) , acquire 50 % ownership venture oil & gas , inc . ambra become 50 % owner property project venture interest . consideration ambra 's purchase 50 % capital stock venture inc . one million shares ambra common stock . part acquisition , venture assign ambra , 50 % interest bastian bay field prospect , state lease \" 9800 \" . 1 , plaquemine parish , louisiana . additional project assign ambra venture ambra shall right request assignment 50 % interest retain venture various project . primary business venture inc . acquire oil gas property re-mediation re-completion work result enhance recovery rate bring back commercial production . current economic condition petroleum industry facilitate acquisition property larger produce company declare surplus property . ambra venture inc . favorable position able acquire property while inventory offering high level . venture currently negotiate acquisition multiple oil gas project texa , louisiana oklahoma , party anticipate add significantly ambra 's resource base productive project . board director john m . hickey , president contact : ambra resource group inc . investor relation : 800-698 - 3377 604-669 - 2723 web site : http : / / www . ambraresource . com release informational purpose . offer sell solicit security product kind . release include information constitute forward-look statement pursuant safe harbor provision private security litigation reform act 1995 . forward-look statement involve risk uncertainty cause actual result differ materially future result encompass within forward-look statement . material provide ambra resource group inc . \" \" basis . ambra resource group inc . expressly disclaim warranty , express imply , include without limitation , warranty merchantability fitness particular purpose , respect service material product . event shall ambra resource group inc . liable direct , indirect , incidental , punitive consequential damages kind whatsoever respect service , material product . trinity venture , inc . receive fee $ 5 , 0 distribute document . permanently remove e-mail address our file call fax us toll free 877-393 - 7237 ; click \" reply \" put \" remove \" subject .\n",
    "'''\n",
    "pred = infrence(test1)\n",
    "print(\"spam\" if pred == 1 else \"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:49:41.118279Z",
     "iopub.status.busy": "2025-10-20T11:49:41.118003Z",
     "iopub.status.idle": "2025-10-20T11:49:41.155249Z",
     "shell.execute_reply": "2025-10-20T11:49:41.154451Z",
     "shell.execute_reply.started": "2025-10-20T11:49:41.118252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\n"
     ]
    }
   ],
   "source": [
    "test2 = '''Subject: postdoc position groningen , netherland\n",
    "\n",
    "job position : postdoc dept . social pharmacy pharmacoepidemiology , groningen institute drug study , faculty mathematic natural science , netherland . description work group social pharmacy pharmacoepidemiology perform fundamental apply research epidemiological medical literature database order determine effectiveness / side-effect profile drug . post-doc ask participate program develop computer text analysis pattern recognition technique extraction ( side ) effect profile drug pharmaceutical medical electronic literature database : ( 1 ) source information lead innovative drug research ; ( 2 ) determine benefit-risk profile drug . phd - student assign program . requirement computer linguist computer scientist , complete phd - project expertise corpus linguistics , mathematical linguistics intelligent information retrieval ; interest pharmaceutical science innovative drug research ; expertise datum mine pattern recognition method desire . remark salary basis ministry guideline minimum dfl . 3844 , - maximum dfl . f . 7 . 125 , - ( schaal 10 / 11 rwoo ) bruto pro month , dependent education experience . work group social pharmacy pharmacoepidemiology part dutch school ' groningen - utrecht institute drug exploration ' ( guide ) , acknowledge royal dutch academy science . appointment two . information project : prof . dr . r . vo , email : r . vo @ farm . rug . nl ; tel . + 31 . 50 . 3633331 / 3633272 ; fax . + 31 . 50 . 3633311 . reaction . s . . p . , preferably before july 1st , 1997 . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - marc weeber http : / / www . farm . rug . nl / marc / home . html groningen university centre pharmacy marc @ farm . rug . nl social pharmacy pharmacoepidemiology tel : + 31 50 3637571 _ _ _ . deusinglaan 2 fax : + 31 50 3633311 | 9713 aw groningen , netherland - - - - - - - - - - - - - - - - - - - - - 0 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "'''\n",
    "pred = infrence(test2)\n",
    "print(\"spam\" if pred == 1 else \"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

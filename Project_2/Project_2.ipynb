{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data from public real estate websites, build a property selling price predictor for a city, which is, in my case, Chicago. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the Python Library HomeHarvest, which scrapes data from Realtors.com, Zillow, and Redfin. I used it to scrap for any homes sold, pending, or for sale in Chicago. Then, I saved the data as a csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homeharvest import scrape_property\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"HomeHarvest_{current_timestamp}.csv\"\n",
    "\n",
    "sold_properties = scrape_property(\n",
    "    location=\"Chicago, IL\",\n",
    "    listing_type=\"sold\",\n",
    "    past_days=730,\n",
    ")\n",
    "print(f\"Number of sold properties: {len(sold_properties)}\")\n",
    "print(sold_properties.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_properties = scrape_property(\n",
    "    location=\"Chicago, IL\",\n",
    "    listing_type=\"pending\",\n",
    "    past_days=730,\n",
    ")\n",
    "print(f\"Number of pending properties: {len(pending_properties)}\")\n",
    "print(pending_properties.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_sale_properties = scrape_property(\n",
    "    location=\"Chicago, IL\",\n",
    "    listing_type=\"for_sale\",\n",
    "    past_days=730,\n",
    ")\n",
    "print(f\"Number of for sale properties: {len(for_sale_properties)}\")\n",
    "print(for_sale_properties.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([sold_properties, pending_properties, for_sale_properties])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"raw_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"property_id\", \"formatted_address\", \"zip_code\", \"style\", \"beds\", \n",
    "                           \"full_baths\", \"half_baths\", \"sqft\", \"year_built\", \n",
    "                           \"list_price\", \"sold_price\"]]\n",
    "\n",
    "df = df.dropna(subset=['zip_code', \"list_price\", \"sold_price\", \"sqft\", \"beds\", \"full_baths\"])\n",
    "print(len(df))\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've taken the dataset and some of the columns I've estimated will have the greatest value in this predictor. After dropping the nan values within a few important columns, my dataset is down to 10,383. After dropping all the duplicate values, I'm down to 8779 properties. This is a signifcant decrease from my original count of 22,719. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of the columns I got are less important and will NOT be used for training, just identification purposes, like formatting address and property id. Zip code and style will need to be one-hot-encoded since they are categorical variables, and I'll combined full and half baths into a single baths column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] = datetime.now().year - df[\"year_built\"]\n",
    "df.drop(columns=\"year_built\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at diff between sold and list price\n",
    "# predicting sold price\n",
    "\n",
    "# outlier calcs\n",
    "outlier_upper = df[\"sold_price\"].mean() + (2 * df[\"sold_price\"].std())\n",
    "outlier_lower = df[\"sold_price\"].mean() - (2 * df[\"sold_price\"].std())\n",
    "print(f\"Outlier bounds: {outlier_lower} - {outlier_upper}\")\n",
    "\n",
    "outliers = df[(df[\"sold_price\"] > outlier_upper) | (df[\"sold_price\"] < outlier_lower)]\n",
    "print(\"Outliers:\", outliers[[\"formatted_address\", \"sold_price\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating statistical outlier bounds gives us a sold price outlier of 0 - around 2 million. This is a very large range and is most likely due to Chicago's diverse housing market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_code vs. price\n",
    "# would indicate richer zip codes\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "grouped_data = df.groupby(\"zip_code\", as_index=False)[\"sold_price\"].mean()\n",
    "\n",
    "plt.bar(grouped_data[\"zip_code\"], grouped_data[\"sold_price\"])\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Zip Codes\")\n",
    "plt.ylabel(\"Mean Sold Price (in 100k)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zipcodes need to be one-hot-encoded.\n",
    "The highest mean selling price has a zipcode of 60614, and the lowest is 60827. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style vs. price\n",
    "# larger homes, pricier\n",
    "\n",
    "grouped_data = df.groupby(\"style\", as_index=False)[\"sold_price\"].mean()\n",
    "\n",
    "plt.bar(grouped_data[\"style\"], grouped_data[\"sold_price\"])\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Style of House\")\n",
    "plt.ylabel(\"Mean Sold Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trends seem to make sense, with houses being higher than condos or single family houses. However, this metric might just be easier to figure out using the number of beds and baths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beds vs. price\n",
    "# more beds, higher price\n",
    "\n",
    "grouped_data = df.groupby(\"beds\", as_index=False)[\"sold_price\"].mean()\n",
    "\n",
    "plt.bar(grouped_data[\"beds\"], grouped_data[\"sold_price\"])\n",
    "\n",
    "plt.xlabel(\"Number of Beds\")\n",
    "plt.ylabel(\"Mean Sold Price in millions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sold price does increase and act as intended until about 7 rooms, and then it starts to go a little weird. 10 rooms has the maximum mean sold price, but 8, 11, and 14, which are all supposed to be high according to the trend, are very low, about the same price as the 5 room properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baths vs. price\n",
    "# more baths, higher price\n",
    "df[\"baths\"] = df[\"full_baths\"] + (df[\"half_baths\"] * 0.5).bfill()\n",
    "\n",
    "grouped_data = df.groupby(\"baths\", as_index=False)[\"sold_price\"].mean()\n",
    "\n",
    "plt.bar(grouped_data[\"baths\"], grouped_data[\"sold_price\"])\n",
    "\n",
    "plt.xlabel(\"Number of Baths\")\n",
    "plt.ylabel(\"Mean Sold Price in millions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attribute does mostly follow the trend of increases rooms with increasing prices. It has a peak at around 8 baths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined bath + beds vs. sold price\n",
    "# more rooms, higher price\n",
    "\n",
    "df[\"numOfRooms\"] = df[\"baths\"] + df[\"beds\"]\n",
    "\n",
    "grouped_data = df.groupby(\"numOfRooms\", as_index=False)[\"sold_price\"].mean()\n",
    "\n",
    "plt.bar(grouped_data[\"numOfRooms\"], grouped_data[\"sold_price\"])\n",
    "\n",
    "plt.xlabel(\"Number of Rooms\")\n",
    "plt.ylabel(\"Mean Sold Price in millions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to follow the trend, but there are some odd lower values at some points, like at 16 and 24 rooms. Not sure why the trend doesn't apply at this higher room counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft vs. sold price\n",
    "# bigger house, higher price\n",
    "\n",
    "grouped_data = df.groupby(\"sqft\", as_index=False)[\"sold_price\"].mean()\n",
    "\n",
    "plt.plot(grouped_data[\"sqft\"], grouped_data[\"sold_price\"])\n",
    "\n",
    "plt.xlabel(\"Property Area in sqft\")\n",
    "plt.ylabel(\"Mean Sold Price in millions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attribute follows the trend as predicted. There are outliers for the properties with 15000 sqft which goes down, so it's a similar phenomenon as the bath and bed room issue of going down at extremely high values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age vs. sold price\n",
    "# newer houses, higher price\n",
    "\n",
    "grouped_data = df.groupby(\"age\", as_index=False)[\"sold_price\"].mean()\n",
    "\n",
    "plt.plot(grouped_data[\"age\"], grouped_data[\"sold_price\"])\n",
    "\n",
    "plt.xlabel(\"Age of Property\")\n",
    "plt.ylabel(\"Mean Sold Price in millions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attribute has a lot of variation in the trend. The price is higher if the property is new, as expected, but it also seems to peak around 150 years in age, which might be able to be attributed to larger properties being older like historical buildings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = df.groupby(\"age\", as_index=False)[[\"sold_price\", \"sqft\"]].mean()\n",
    "\n",
    "plt.scatter(grouped_data[\"age\"], grouped_data[\"sold_price\"], c=grouped_data[\"sqft\"], cmap='viridis', s=100, alpha=0.8)\n",
    "plt.colorbar(label='Property Area')\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Mean Sold Price in millions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second graph actually doesn't follow the trend I expected it would. There is no discernable correlation between property area and the age. Some newer properties are very large, and so are some that are around 150 years old. There is a single outlier with an age of 250 years, a medium-size area, and a low price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking through the statistics, I've determined the features I'll be including to maximize prediction accuracy and minimize parameter count are zip code, number of rooms, property area, and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i've already dropped the nans\n",
    "model_df = df[[\"sold_price\", \"zip_code\", \"numOfRooms\", \"sqft\", \"age\"]].convert_dtypes().fillna(0)\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode\n",
    "model_df[\"zip_factorized\"], unique_categories = pd.factorize(model_df['zip_code'])\n",
    "model_df.drop(\"zip_code\", inplace=True, axis=1)\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 models I want to try:\n",
    "1. Random Forest Regressor\n",
    "2. Linear Multivariate Regressor\n",
    "3. Ridge/Lasso Regressor\n",
    "4. Support Vector Regression\n",
    "5. KNN Regressor\n",
    "\n",
    "I will use cross validation to determine which model to use for the final product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infrence(prams):\n",
    "    results = m.run(prams)\n",
    "    return results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
